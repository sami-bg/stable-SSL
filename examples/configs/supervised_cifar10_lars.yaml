
data:
  train_on: base
  base:
    name: CIFAR10
    batch_size: 256
    drop_last: True
    shuffle: True
    split: train
    num_workers: 10
    transforms:
      view1:
      - name: RandomResizedCrop
        kwargs:
          size: 32
          scale:
            - 0.1
            - 0.2
      - name: RandomHorizontalFlip
      - name: SpeckleNoise
        kwargs:
          severity: 2
        p: 0.5
      - name: GaussianBlur
        kwargs:
          kernel_size: 5
        p: 0.2
  test_in:
    name: CIFAR10
    batch_size: 32
    drop_last: False
    split: train
    num_workers: 10
  test_out:
    name: CIFAR10
    batch_size: 32
    drop_last: False
    num_workers: 10
    split: test

model:
  name: Supervised
  backbone_model: resnet9

optim:
  epochs: 100
  batch_size: 256
  lr: 1.0
  optimizer: LARS

log:
  folder: ./new_logs
  wandb_project: supervised_cifar10

hardware:
  seed: 0
  float16: true
  # launcher: torch_distributed
  # cpus_per_task: 1
  # gpus_per_task: 1
  # tasks_per_node: 1
  # timeout_min: 60
  # partition: gpu
  # mem_gb: 30
