from contextlib import contextmanager
from random import getstate, setstate
from random import seed as rseed
from typing import Iterable

import numpy as np
import torch
from torch.utils.data import Dataset


def set_seed(seeds):
    if hasattr(seeds[0], "__len__"):
        version, state, gauss = seeds[0]
        setstate((version, tuple(state), gauss))
    else:
        rseed(seeds[0])
    if hasattr(seeds[1], "__len__"):
        np.random.set_state(seeds[1])
    else:
        np.random.seed(seeds[1])
    if hasattr(seeds[2], "__len__"):
        torch.set_rng_state(seeds[2])
    else:
        torch.manual_seed(seeds[2])
    if len(seeds) == 4:
        if hasattr(seeds[3], "__len__"):
            torch.cuda.set_rng_state_all(seeds[3])
        else:
            torch.cuda.manual_seed(seeds[3])


@contextmanager
def random_seed(seed):
    seeds = [getstate(), np.random.get_state(), torch.get_rng_state()]
    # for now we don't use that functionality since it creates issues
    # with DataLoader and multiple processes...
    # RuntimeError: Cannot re-initialize CUDA in forked subprocess.
    # To use CUDA with multiprocessing, you must use the 'spawn' start method
    if False:  # torch.cuda.is_available():
        seeds.append(torch.cuda.get_rng_state_all())
    new_seeds = [int(seed)] * len(seeds)
    set_seed(new_seeds)
    yield
    set_seed(seeds)


class DictFormat(Dataset):
    """Format dataset to ensure dictionary-based item access."""

    def __init__(self, dataset: Iterable):
        self.dataset = dataset
        assert type(dataset) not in [
            DictFormat,
            AddTransform,
        ]
        # self.original = dataset

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        image, label = self.dataset[idx]
        sample = dict(image=image, label=label, idx=idx)
        return sample


class AddTransform(Dataset):
    """Add a transform to a dataset.

    Args:
        dataset (Iterable): Dataset to apply transforms to.
        transform (callable): Transform to be applied on a sample.
    """

    def __init__(self, dataset: Iterable, transform: callable):
        assert type(dataset) in [
            DictFormat,
            AddTransform,
        ]
        assert callable(transform)
        self.dataset = dataset
        self.transform = transform
        # self.original = dataset.original

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        sample = self.dataset[idx]
        sample = self.transform(sample)
        return sample
